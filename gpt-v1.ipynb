{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52987294-cf0b-4b39-a03f-48422336ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenneth\\AppData\\Local\\Temp\\ipykernel_25144\\1860295898.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "max_iters = 200\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 100\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45887504-b1a1-49d5-83d2-165762247c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ----------\n",
      "anyio                     4.2.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.2.0\n",
      "Babel                     2.14.0\n",
      "beautifulsoup4            4.12.2\n",
      "bleach                    6.1.0\n",
      "Brotli                    1.0.9\n",
      "certifi                   2023.11.17\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        2.0.4\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.1\n",
      "cryptography              41.0.7\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.19.1\n",
      "filelock                  3.13.1\n",
      "fqdn                      1.5.1\n",
      "fsspec                    2023.4.0\n",
      "gmpy2                     2.1.2\n",
      "idna                      3.4\n",
      "ipykernel                 6.28.0\n",
      "ipython                   8.19.0\n",
      "ipywidgets                8.1.1\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.2\n",
      "json5                     0.9.14\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.20.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.0\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.0\n",
      "jupyter-events            0.9.0\n",
      "jupyter-lsp               2.2.1\n",
      "jupyter_server            2.12.2\n",
      "jupyter_server_terminals  0.5.1\n",
      "jupyterlab                4.0.10\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.25.2\n",
      "jupyterlab-widgets        3.0.9\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib-inline         0.1.6\n",
      "mistune                   3.0.2\n",
      "mkl-fft                   1.3.8\n",
      "mkl-random                1.2.4\n",
      "mkl-service               2.4.0\n",
      "mpmath                    1.3.0\n",
      "nbclient                  0.9.0\n",
      "nbconvert                 7.14.0\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.8\n",
      "networkx                  3.1\n",
      "notebook                  7.0.6\n",
      "notebook_shim             0.2.3\n",
      "numpy                     1.26.3\n",
      "overrides                 7.4.0\n",
      "packaging                 23.2\n",
      "pandas                    2.2.0\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.3\n",
      "Pillow                    10.0.1\n",
      "pip                       23.3.1\n",
      "platformdirs              4.1.0\n",
      "prometheus-client         0.19.0\n",
      "prompt-toolkit            3.0.43\n",
      "psutil                    5.9.7\n",
      "pure-eval                 0.2.2\n",
      "pycparser                 2.21\n",
      "Pygments                  2.17.2\n",
      "pyOpenSSL                 23.2.0\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.8.2\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.1\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.12\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.2\n",
      "qtconsole                 5.5.1\n",
      "QtPy                      2.4.1\n",
      "referencing               0.32.0\n",
      "requests                  2.31.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.16.2\n",
      "Send2Trash                1.8.2\n",
      "setuptools                68.2.2\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.3\n",
      "sympy                     1.12\n",
      "terminado                 0.18.0\n",
      "tinycss2                  1.2.1\n",
      "torch                     2.2.0\n",
      "torchaudio                2.2.0\n",
      "torchvision               0.17.0\n",
      "tornado                   6.4\n",
      "traitlets                 5.14.1\n",
      "types-python-dateutil     2.8.19.14\n",
      "typing_extensions         4.7.1\n",
      "tzdata                    2023.4\n",
      "uri-template              1.3.0\n",
      "urllib3                   1.26.18\n",
      "wcwidth                   0.2.12\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.7.0\n",
      "wheel                     0.41.2\n",
      "widgetsnbextension        4.0.9\n",
      "win-inet-pton             1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef33a82-302c-485e-8c8f-6c46364ae5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = \"\"\n",
    "with open(r\"C:\\Users\\Kenneth\\Desktop\\python_projects\\gpt-course\\Large-Language-Model\\vocab.txt\", encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        chars = sorted(list(set(text)))\n",
    "        \n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de610ef-a793-4a63-8056-b7223caa2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa487d-1a08-45ed-95d0-76d20fa6a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_chunk(split):\n",
    "    filename = \"openwebtext/train_split.txt\" if split == 'train' else \"openwebtext/val_split.txt\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "            # Determine the file size and a random position to start reading\n",
    "            file_size = len(mm)\n",
    "            start_pos = random.randint(0, (file_size) - block_size*batch_size)\n",
    "\n",
    "            # Seek to the random position and read the block of text\n",
    "            mm.seek(start_pos)\n",
    "            block = mm.read(block_size*batch_size-1)\n",
    "\n",
    "            # Decode the block to a string, ignoring any invalid byte sequences\n",
    "            decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "            \n",
    "            # Train and test splits\n",
    "            data = torch.tensor(encode(decoded_block), dtype=torch.long)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def get_batch(split):\n",
    "    data = get_random_chunk(split)\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a62730-b4ee-4a2f-bfca-78280ef5fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" This class represents one head of self-attention, a crucial component in \n",
    "    Transformer models for tasks such as natural language processing. \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        '''They transform the input embeddings (n_embd) into keys, queries, and values for the attention mechanism.'''\n",
    "        super().__init__() #  This defines the constructor method\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) \n",
    "        #This matrix is used to construct a causal mask ensuring that during self-attention, each position can only attend to positions before it in the sequence.\n",
    "        self.dropout = nn.Dropout(dropout) # Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of input units to zero during training.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape # Obtains the batch size (B), sequence length (T), and input embedding size (C) from the input tensor x.\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T) #  It performs a dot product between queries and keys, scaled by the square root of the key size.\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T) \n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707c2d4-9645-43e9-a87e-cacfa7199526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Head class\n",
    "head_size = 64  # Example head size\n",
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "embedding_size = 128\n",
    "\n",
    "# Create an instance of the Head class\n",
    "head = Head(head_size)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(batch_size, sequence_length, embedding_size)\n",
    "\n",
    "# Pass the input data through the Head instance\n",
    "output = head(input_data)\n",
    "\n",
    "# Verify the shape of the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
