{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52987294-cf0b-4b39-a03f-48422336ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenneth\\AppData\\Local\\Temp\\ipykernel_14724\\1860295898.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "max_iters = 200\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 100\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef33a82-302c-485e-8c8f-6c46364ae5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = \"\"\n",
    "with open(r\"C:\\Users\\Kenneth\\Desktop\\python_projects\\gpt-course\\Large-Language-Model\\vocab.txt\", encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        chars = sorted(list(set(text)))\n",
    "        \n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de610ef-a793-4a63-8056-b7223caa2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edaa487d-1a08-45ed-95d0-76d20fa6a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_chunk(split):\n",
    "    filename = \"openwebtext/train_split.txt\" if split == 'train' else \"openwebtext/val_split.txt\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "            # Determine the file size and a random position to start reading\n",
    "            file_size = len(mm)\n",
    "            start_pos = random.randint(0, (file_size) - block_size*batch_size)\n",
    "\n",
    "            # Seek to the random position and read the block of text\n",
    "            mm.seek(start_pos)\n",
    "            block = mm.read(block_size*batch_size-1)\n",
    "\n",
    "            # Decode the block to a string, ignoring any invalid byte sequences\n",
    "            decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "            \n",
    "            # Train and test splits\n",
    "            data = torch.tensor(encode(decoded_block), dtype=torch.long)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def get_batch(split):\n",
    "    data = get_random_chunk(split)\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a62730-b4ee-4a2f-bfca-78280ef5fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" This class represents one head of self-attention, a crucial component in \n",
    "    Transformer models for tasks such as natural language processing. \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        '''They transform the input embeddings (n_embd) into keys, queries, and values for the attention mechanism.'''\n",
    "        super().__init__() #  This defines the constructor method\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) \n",
    "        #This matrix is used to construct a causal mask ensuring that during self-attention, each position can only attend to positions before it in the sequence.\n",
    "        self.dropout = nn.Dropout(dropout) # Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of input units to zero during training.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape # Obtains the batch size (B), sequence length (T), and input embedding size (C) from the input tensor x.\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T) #  It performs a dot product between queries and keys, scaled by the square root of the key size.\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)  # Applies a mask to the attention scores to ensure causality, i.e., each position can only attend to positions before it in the sequence.\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T) #  Applies a softmax function to obtain the attention weights.\n",
    "        wei = self.dropout(wei) #  Applies dropout to the attention weights for regularization.\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs) #  Computes the weighted sum of values using the attention weights.\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dddc7a5-88ba-4e74-a666-91f4c83bd54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1904e-01,  6.9782e-01,  7.3202e-01,  3.5143e-01,  4.4436e-02,\n",
       "          5.2613e-01,  1.5634e-01, -3.5303e-01, -3.9407e-01,  1.9041e-01,\n",
       "          2.2973e-01,  1.7658e-01,  1.3151e-01, -5.9906e-02, -1.0874e+00,\n",
       "         -1.8509e-01,  1.2523e-01, -2.2777e-01, -2.5571e-01, -4.9634e-01,\n",
       "          4.5730e-01, -6.0723e-02, -2.7428e-01, -7.7702e-01, -6.6218e-01,\n",
       "         -3.6696e-01,  5.6800e-01, -5.1916e-01,  5.9357e-01,  3.7748e-02,\n",
       "         -1.8416e-01, -2.2452e-01,  3.7481e-01,  1.2914e+00, -6.4070e-01,\n",
       "          5.8648e-02,  2.4736e-01, -8.6550e-01,  2.2037e-01, -2.7817e-01,\n",
       "          2.6035e-01,  2.7013e-02,  1.5147e-01,  8.1801e-01,  2.1250e-01,\n",
       "          3.5440e-01,  4.5542e-01,  2.8009e-01,  5.7474e-01,  1.7505e-01,\n",
       "         -3.0871e-01,  3.0342e-01,  7.8115e-01, -7.2455e-01, -4.6063e-01,\n",
       "         -6.3669e-01, -8.0901e-01, -2.2819e-01,  8.7427e-01, -9.2265e-01,\n",
       "         -2.7668e-02, -5.6819e-01, -9.0677e-01, -1.7622e-01],\n",
       "        [ 7.6219e-04,  6.2601e-02, -1.5429e-01, -8.6859e-01,  7.9366e-01,\n",
       "         -2.1071e-01, -1.1342e+00,  5.3798e-01, -1.4317e-01, -5.0229e-01,\n",
       "          2.1904e-01, -2.9981e-01,  7.6297e-01,  1.4502e+00, -7.3834e-01,\n",
       "          4.4498e-01, -1.2112e-01, -4.0124e-01,  2.0834e-01, -2.5405e-01,\n",
       "         -1.7391e-01,  2.1839e-01,  2.3652e-01, -1.2654e+00, -4.4179e-01,\n",
       "         -5.6986e-01,  5.8984e-02,  7.7393e-01,  9.0866e-02, -6.5888e-01,\n",
       "          3.9204e-01,  8.3703e-01,  1.0508e-02, -3.5624e-01,  2.6685e-01,\n",
       "          1.5189e-01, -2.1252e-01,  5.0525e-01, -8.4747e-01, -1.5747e-02,\n",
       "          5.7923e-01, -8.4549e-01,  4.3830e-01,  8.4019e-01,  7.2151e-02,\n",
       "          1.6373e+00,  3.5745e-01, -5.7600e-01, -2.4916e-01, -7.7306e-01,\n",
       "          2.1263e-01, -3.2174e-01,  3.1455e-01,  8.4430e-01, -6.8637e-01,\n",
       "         -1.1915e-01,  2.3486e-01,  4.3528e-01, -7.9595e-01,  2.6208e-01,\n",
       "         -4.3016e-01,  7.5784e-02, -4.3078e-01,  5.3386e-01]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the input dimensions\n",
    "n_embd = 128  # Input embedding size\n",
    "head_size = 64  # Head size for linear transformation\n",
    "\n",
    "# Create an instance of nn.Linear\n",
    "linear_layer = nn.Linear(n_embd, head_size, bias=False)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(2, n_embd)  # Example batch size of 2\n",
    "\n",
    "# Pass the input data through the linear layer\n",
    "output_data = linear_layer(input_data)\n",
    "\n",
    "# Display the output value\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1707c2d4-9645-43e9-a87e-cacfa7199526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test the Head class\n",
    "head_size = 64  # Example head size\n",
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "embedding_size = 128\n",
    "\n",
    "# Create an instance of the Head class\n",
    "head = Head(head_size)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(batch_size, sequence_length, embedding_size)\n",
    "\n",
    "# Pass the input data through the Head instance\n",
    "output = head(input_data)\n",
    "\n",
    "# Verify the shape of the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f809e8-7430-4d19-b79d-92703ee1644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size): #  It takes two arguments: num_heads and head_size.\n",
    "        super().__init__() #  This defines the constructor method\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)]) # This creates a list of num_heads instances of the Head class. Each instance represents one head of self-attention.\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd) #  This defines a linear transformation layer (nn.Linear) that projects the concatenated outputs of the individual heads back to the original embedding dimension n_embd.\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3]) #  applies each head of self-attention (h(x)) to the input tensor x and concatenates the outputs along the last dimension (dim=-1)\n",
    "        print(out.shape)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bcec97e-4f44-4bfc-bdf5-eb11f845f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([3, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create an instance of nn.Linear\n",
    "linear_layer = nn.Linear(in_features=100, out_features=50)  # Input size = 100, Output size = 50\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(3, 100)  # Batch size = 32, Number of input features = 100\n",
    "\n",
    "# Pass the input data through the linear layer\n",
    "output_data = linear_layer(input_data)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(\"Output shape:\", output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77234729-eacc-4b2b-b65c-00659e7dec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n",
      "Output shape: torch.Size([2, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the parameters (replace these with your actual values)\n",
    "n_embd = 128\n",
    "num_heads = 4\n",
    "head_size = 32\n",
    "dropout = 0.1\n",
    "\n",
    "# Create an instance of the MultiHeadAttention class\n",
    "multihead_attention = MultiHeadAttention(num_heads, head_size)\n",
    "\n",
    "# Generate some random input data\n",
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "input_data = torch.randn(batch_size, sequence_length, n_embd)\n",
    "\n",
    "# Pass the input data through the MultiHeadAttention instance\n",
    "output = multihead_attention(input_data)\n",
    "\n",
    "# Verify the shape of the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c369e9-306a-4245-baef-d9c41b434944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd), #  This expansion introduces more capacity and allows the model to capture complex patterns.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "931dbf31-f4e2-4c33-8f64-f4b90b83869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 10])\n",
      "Output values:\n",
      "tensor([[ 0.1012, -0.2529,  0.2376, -0.2995, -0.0338,  0.1090,  0.0056,  0.4771,\n",
      "          0.0851,  0.3686],\n",
      "        [-0.1713, -0.2474, -0.0276,  0.0781,  0.1991,  0.0000, -0.0584, -0.0044,\n",
      "         -0.1147, -0.0005]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the input embedding dimensionality\n",
    "n_embd = 10  # Example value\n",
    "\n",
    "# Define dropout probability (assuming it's defined somewhere in your code)\n",
    "dropout = 0.1  # Example value\n",
    "\n",
    "# Create an instance of the FeedForward class\n",
    "feedforward_model = FeedFoward(n_embd)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(2, n_embd)  # Example batch size of 2\n",
    "\n",
    "# Pass the input data through the model\n",
    "output_data = feedforward_model(input_data)\n",
    "\n",
    "# Print the shape of the output tensor and its values\n",
    "print(\"Output shape:\", output_data.shape)\n",
    "print(\"Output values:\")\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1625a9e-fe8a-4651-9e35-d30d67a899b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size) # A Multi-Head Self-Attention layer (MultiHeadAttention) with n_head heads and head_size size.\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y) # Residual connection adds the input x with the output y\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5ec7bf-8c7f-414d-b99a-5db8c86aa043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n",
      "Output shape: torch.Size([2, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "# Define some parameters\n",
    "n_embd = 128\n",
    "n_head = 8\n",
    "sequence_length = 10\n",
    "batch_size = 2\n",
    "\n",
    "# Create an instance of the Block class\n",
    "block = Block(n_embd, n_head)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(batch_size, sequence_length, n_embd)\n",
    "\n",
    "# Pass the input data through the Block instance\n",
    "output = block(input_data)\n",
    "\n",
    "# Verify the shape of the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "501941af-b1df-44fc-8376-70137d6fb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0748b23-17fc-4972-9178-83ca7713e4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
