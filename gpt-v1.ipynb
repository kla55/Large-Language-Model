{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52987294-cf0b-4b39-a03f-48422336ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenneth\\AppData\\Local\\Temp\\ipykernel_25144\\1860295898.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "max_iters = 200\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 100\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45887504-b1a1-49d5-83d2-165762247c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ----------\n",
      "anyio                     4.2.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.2.0\n",
      "Babel                     2.14.0\n",
      "beautifulsoup4            4.12.2\n",
      "bleach                    6.1.0\n",
      "Brotli                    1.0.9\n",
      "certifi                   2023.11.17\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        2.0.4\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.1\n",
      "cryptography              41.0.7\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.19.1\n",
      "filelock                  3.13.1\n",
      "fqdn                      1.5.1\n",
      "fsspec                    2023.4.0\n",
      "gmpy2                     2.1.2\n",
      "idna                      3.4\n",
      "ipykernel                 6.28.0\n",
      "ipython                   8.19.0\n",
      "ipywidgets                8.1.1\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.2\n",
      "json5                     0.9.14\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.20.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.0\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.0\n",
      "jupyter-events            0.9.0\n",
      "jupyter-lsp               2.2.1\n",
      "jupyter_server            2.12.2\n",
      "jupyter_server_terminals  0.5.1\n",
      "jupyterlab                4.0.10\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.25.2\n",
      "jupyterlab-widgets        3.0.9\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib-inline         0.1.6\n",
      "mistune                   3.0.2\n",
      "mkl-fft                   1.3.8\n",
      "mkl-random                1.2.4\n",
      "mkl-service               2.4.0\n",
      "mpmath                    1.3.0\n",
      "nbclient                  0.9.0\n",
      "nbconvert                 7.14.0\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.8\n",
      "networkx                  3.1\n",
      "notebook                  7.0.6\n",
      "notebook_shim             0.2.3\n",
      "numpy                     1.26.3\n",
      "overrides                 7.4.0\n",
      "packaging                 23.2\n",
      "pandas                    2.2.0\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.3\n",
      "Pillow                    10.0.1\n",
      "pip                       23.3.1\n",
      "platformdirs              4.1.0\n",
      "prometheus-client         0.19.0\n",
      "prompt-toolkit            3.0.43\n",
      "psutil                    5.9.7\n",
      "pure-eval                 0.2.2\n",
      "pycparser                 2.21\n",
      "Pygments                  2.17.2\n",
      "pyOpenSSL                 23.2.0\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.8.2\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.1\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.12\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.2\n",
      "qtconsole                 5.5.1\n",
      "QtPy                      2.4.1\n",
      "referencing               0.32.0\n",
      "requests                  2.31.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.16.2\n",
      "Send2Trash                1.8.2\n",
      "setuptools                68.2.2\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.3\n",
      "sympy                     1.12\n",
      "terminado                 0.18.0\n",
      "tinycss2                  1.2.1\n",
      "torch                     2.2.0\n",
      "torchaudio                2.2.0\n",
      "torchvision               0.17.0\n",
      "tornado                   6.4\n",
      "traitlets                 5.14.1\n",
      "types-python-dateutil     2.8.19.14\n",
      "typing_extensions         4.7.1\n",
      "tzdata                    2023.4\n",
      "uri-template              1.3.0\n",
      "urllib3                   1.26.18\n",
      "wcwidth                   0.2.12\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.7.0\n",
      "wheel                     0.41.2\n",
      "widgetsnbextension        4.0.9\n",
      "win-inet-pton             1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef33a82-302c-485e-8c8f-6c46364ae5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = \"\"\n",
    "with open(r\"C:\\Users\\Kenneth\\Desktop\\python_projects\\gpt-course\\Large-Language-Model\\vocab.txt\", encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        chars = sorted(list(set(text)))\n",
    "        \n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de610ef-a793-4a63-8056-b7223caa2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa487d-1a08-45ed-95d0-76d20fa6a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_chunk(split):\n",
    "    filename = \"openwebtext/train_split.txt\" if split == 'train' else \"openwebtext/val_split.txt\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "            # Determine the file size and a random position to start reading\n",
    "            file_size = len(mm)\n",
    "            start_pos = random.randint(0, (file_size) - block_size*batch_size)\n",
    "\n",
    "            # Seek to the random position and read the block of text\n",
    "            mm.seek(start_pos)\n",
    "            block = mm.read(block_size*batch_size-1)\n",
    "\n",
    "            # Decode the block to a string, ignoring any invalid byte sequences\n",
    "            decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "            \n",
    "            # Train and test splits\n",
    "            data = torch.tensor(encode(decoded_block), dtype=torch.long)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def get_batch(split):\n",
    "    data = get_random_chunk(split)\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39a62730-b4ee-4a2f-bfca-78280ef5fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" This class represents one head of self-attention, a crucial component in \n",
    "    Transformer models for tasks such as natural language processing. \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        '''They transform the input embeddings (n_embd) into keys, queries, and values for the attention mechanism.'''\n",
    "        super().__init__() #  This defines the constructor method\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) \n",
    "        #This matrix is used to construct a causal mask ensuring that during self-attention, each position can only attend to positions before it in the sequence.\n",
    "        self.dropout = nn.Dropout(dropout) # Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of input units to zero during training.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape # Obtains the batch size (B), sequence length (T), and input embedding size (C) from the input tensor x.\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T) #  It performs a dot product between queries and keys, scaled by the square root of the key size.\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)  # Applies a mask to the attention scores to ensure causality, i.e., each position can only attend to positions before it in the sequence.\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T) #  Applies a softmax function to obtain the attention weights.\n",
    "        wei = self.dropout(wei) #  Applies dropout to the attention weights for regularization.\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs) #  Computes the weighted sum of values using the attention weights.\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dddc7a5-88ba-4e74-a666-91f4c83bd54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8208,  0.0652,  0.0449, -0.3609,  0.8667, -0.2947, -0.2741,  0.1935,\n",
       "         -0.1948, -0.6649, -0.6063, -0.6419, -0.8821, -0.1561,  0.7525, -0.8079,\n",
       "          0.1865, -0.5883, -0.1600,  0.2688,  0.0817,  0.1296, -1.3025, -0.0581,\n",
       "          0.5290,  0.1444, -0.4970,  1.2848, -1.0528,  0.0347, -0.2273,  0.2239,\n",
       "          0.2425, -0.4471, -0.5768, -0.5690,  0.3356, -0.7686, -0.0229, -0.0316,\n",
       "          0.0594,  0.0431, -0.2735, -0.6617, -0.3064,  0.8235, -0.6719, -0.7312,\n",
       "         -0.3184,  0.2093, -0.6100,  0.0640, -0.5136, -0.7975, -0.3740, -0.5488,\n",
       "         -0.0077,  0.2797,  0.0140,  0.4360, -0.1904,  0.7037,  0.4323, -0.0119],\n",
       "        [-0.4265,  0.2315, -0.6117,  0.4909, -0.2933, -0.6605, -1.3260,  0.4108,\n",
       "         -0.9564, -1.0663, -0.5276, -0.2177,  0.3193, -0.5281, -0.1108,  0.3351,\n",
       "          0.4760, -0.6309,  0.8133, -0.0098, -1.2584,  0.2803,  0.6250,  0.2732,\n",
       "         -0.2160, -0.8056, -0.2183,  0.2993, -0.6386,  1.0062,  0.5774, -0.4043,\n",
       "          0.8505, -0.2440, -1.5985, -0.2495,  1.1105,  0.1272, -0.1184, -0.0805,\n",
       "          0.0658, -0.2421,  0.7562,  0.1380,  0.4826, -0.1702, -0.5501,  1.1455,\n",
       "          0.6013, -0.9807, -0.9413, -0.0899,  0.6940, -0.3217,  0.1114,  0.1895,\n",
       "          0.0019,  0.8704, -0.0623,  0.0363,  0.1424,  1.0243,  0.0956, -0.4628]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the input dimensions\n",
    "n_embd = 128  # Input embedding size\n",
    "head_size = 64  # Head size for linear transformation\n",
    "\n",
    "# Create an instance of nn.Linear\n",
    "linear_layer = nn.Linear(n_embd, head_size, bias=False)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(2, n_embd)  # Example batch size of 2\n",
    "\n",
    "# Pass the input data through the linear layer\n",
    "output_data = linear_layer(input_data)\n",
    "\n",
    "# Display the output value\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1707c2d4-9645-43e9-a87e-cacfa7199526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test the Head class\n",
    "head_size = 64  # Example head size\n",
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "embedding_size = 128\n",
    "\n",
    "# Create an instance of the Head class\n",
    "head = Head(head_size)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(batch_size, sequence_length, embedding_size)\n",
    "\n",
    "# Pass the input data through the Head instance\n",
    "output = head(input_data)\n",
    "\n",
    "# Verify the shape of the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16f809e8-7430-4d19-b79d-92703ee1644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size): #  It takes two arguments: num_heads and head_size.\n",
    "        super().__init__() #  This defines the constructor method\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)]) # This creates a list of num_heads instances of the Head class. Each instance represents one head of self-attention.\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd) #  This defines a linear transformation layer (nn.Linear) that projects the concatenated outputs of the individual heads back to the original embedding dimension n_embd.\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3]) #  applies each head of self-attention (h(x)) to the input tensor x and concatenates the outputs along the last dimension (dim=-1)\n",
    "        print(out.shape)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1bcec97e-4f44-4bfc-bdf5-eb11f845f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create an instance of nn.Linear\n",
    "linear_layer = nn.Linear(in_features=100, out_features=50)  # Input size = 100, Output size = 50\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(32, 100)  # Batch size = 32, Number of input features = 100\n",
    "\n",
    "# Pass the input data through the linear layer\n",
    "output_data = linear_layer(input_data)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(\"Output shape:\", output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77234729-eacc-4b2b-b65c-00659e7dec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n",
      "Output shape: torch.Size([2, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the parameters (replace these with your actual values)\n",
    "n_embd = 128\n",
    "num_heads = 4\n",
    "head_size = 32\n",
    "dropout = 0.1\n",
    "\n",
    "# Create an instance of the MultiHeadAttention class\n",
    "multihead_attention = MultiHeadAttention(num_heads, head_size)\n",
    "\n",
    "# Generate some random input data\n",
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "input_data = torch.randn(batch_size, sequence_length, n_embd)\n",
    "\n",
    "# Pass the input data through the MultiHeadAttention instance\n",
    "output = multihead_attention(input_data)\n",
    "\n",
    "# Verify the shape of the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c369e9-306a-4245-baef-d9c41b434944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931dbf31-f4e2-4c33-8f64-f4b90b83869d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1625a9e-fe8a-4651-9e35-d30d67a899b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e5ec7bf-8c7f-414d-b99a-5db8c86aa043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# To test head class\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the parameters (replace these with your actual values)\n",
    "n_embd = 128\n",
    "head_size = 64\n",
    "block_size = 10\n",
    "dropout = 0.1\n",
    "\n",
    "# Test the Head class\n",
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "\n",
    "# Create an instance of the Head class\n",
    "head = Head(head_size)\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(batch_size, sequence_length, n_embd)\n",
    "\n",
    "# Pass the input data through the Head instance\n",
    "output = head(input_data)\n",
    "\n",
    "# Verify the shape of the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82b2d3af-bb73-4490-9345-39607d3382a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=128, out_features=64, bias=False)\n"
     ]
    }
   ],
   "source": [
    "k = nn.Linear(128, 64, bias=False)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47777c8a-5bcc-457b-ae7f-16c3672d4e86",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m l\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "l = k.transpose(-2, -1)\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501941af-b1df-44fc-8376-70137d6fb099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
